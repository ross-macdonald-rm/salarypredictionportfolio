{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a Data Scientist in the recruitment industry, my goal is to build a system to predict salaries for a new set of job postings based on data provided on a set of historic job postings that include salaries.\n",
    "\n",
    "Two CSV data files are available as a basis for training a machine learning model:\n",
    "\n",
    "• train_features.csv: Each row represents metadata for an individual job posting.\n",
    "The “jobId” column represents a unique identifier for the job posting. The remaining columns describe features of the job posting.\n",
    "• train_salaries.csv: Each row associates a “jobId” with a “salary”.\n",
    "\n",
    "The data upon which predictions should be made are stored in a further CSV data file:\n",
    "\n",
    "• test_features.csv: Similar to train_features.csv, each row represents metadata for an individual job posting.\n",
    "\n",
    "The output of my system should be a CSV file entitled test_salaries.csv where each row has the following format:\n",
    "\n",
    "jobId, salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Importing scikit-learn pre-processing libraries\n",
    "\n",
    "\n",
    "\n",
    "# Importing scikit-learn machine learning libraries\n",
    "\n",
    "\n",
    "\n",
    "# Author information\n",
    "__author__ = \"Ross MacDonald\"\n",
    "__email__ = \"ross.macdonald@technologist.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Reusable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data file with completion dialogue and shape confirmation\n",
    "def load_file(file):\n",
    "    df =  pd.read_csv(file)\n",
    "    shape = df.shape\n",
    "    print(\"Data file is loaded, the shape of the dataset = {}\".format(shape))\n",
    "    return df\n",
    "\n",
    "def ends(df, x):\n",
    "    print('{} rows x {} columns'.format(np.shape(df)[0],np.shape(df)[1]))\n",
    "    return df.head(x).append(df.tail(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into pandas dataframes (csv files for training and test data)\n",
    "train_feature_df = load_file('data/train_features.csv')\n",
    "train_target_df = load_file('data/train_salaries.csv')\n",
    "test_df = load_file('data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data on jobId to get a single training dataset (includes features and target)\n",
    "train_df = pd.merge(train_feature_df,train_target_df,how=\"inner\",on=\"jobId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial check of top 10 rows of train_df to confirm load and get an initial view on data / types\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial check of top 10 rows of test_feature_df to confirm load and get an initial view on data / types\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information on the train_feature_df dataframe. Ensure data types and number of entries per column are as expected.\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information on the train_feature_df dataframe. Ensure data types and number of entries per column are as expected.\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows in train_df\n",
    "print(\"Number of duplicated rows = {}\".format(train_df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows in train_df\n",
    "print(\"Number of duplicated rows = {}\".format(train_df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in the columns of train_df\n",
    "train_df.isnull().sum().to_frame('Null Entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in the columns of test_df\n",
    "test_df.isnull().sum().to_frame('Null Entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are no duplicates or null entries in the data, so no need to drop rows / entries or subsitute any values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names for numerical columns from train_df to enable us to filter for invalid values \n",
    "print(train_df.select_dtypes(include=['float64', 'int64']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having found the column names for numerical columns from train_df, find rows that contain invalid values (i.e. <0 or <=0)\n",
    "print(train_df[(train_df['yearsExperience'] < 0) | (train_df['milesFromMetropolis'] < 0) | (train_df['salary'] <= 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows that contain invalid data from the train_df dataframe (i.e. salary was invalid in all cases, thus only\n",
    "# include rows with salaries more than 0)\n",
    "train_df = train_df[train_df.salary > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe information to confirm that the expected rows have been dropped\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of train_df after dropping the invalid values and print head and tail (using function ends) to confirm\n",
    "# reindex. Makes rows sequential to prevent any misunderstanding in subsequent analysis.\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "ends(train_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Invalid numerical entries have been dropped from the train_df dataframe, ensuring only valid data informs the prediction model / system. Index has been reset to prevent any misunderstanding (due to non-sequential rows in data) in any further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for the training data train_df\n",
    "train_df.salary.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable (salary)\n",
    "plt.figure(figsize = (14, 6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(train_df.salary)\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(train_df.salary, bins=50 , color = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = np.subtract(*np.percentile(train_df.salary, [75, 25]))\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.salary[~((train_df.salary < (Q1 - 1.5 * IQR)) or (train_df.salary > (Q3 + 1.5 * IQR))).any()]\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize each feature variable\n",
    "#summarize the target variable\n",
    "#look for correlation between each feature and the target\n",
    "#look for correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a reasonable metric (MSE in this case)\n",
    "#create an extremely simple model and measure its efficacy\n",
    "#e.g. use \"average salary\" for each industry as your model and then measure MSE\n",
    "#during 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brainstorm 3 models that you think may improve results over the baseline model based\n",
    "#on your "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainstorm 3 models that you think may improve results over the baseline model based on your EDA and explain why they're reasonable solutions here.\n",
    "\n",
    "Also write down any new features that you think you should try adding to the model based on your EDA, e.g. interaction variables, summary statistics for each group, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and tune the models that you brainstormed during part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do 5-fold cross validation on models and measure MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"prodcuction\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
